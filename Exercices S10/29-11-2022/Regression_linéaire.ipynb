{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application d'un modèle de régression linéaire sur un dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sns.load_dataset('tips')  # On récupère ici le dataset 'tips' de seaborn\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On veut determiner s'il existe une corrélation entre les pourboires ('tip') et les données des autres colonnes ('total_bill', 'sex', 'smoker', 'day', 'time' et 'size')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['tip']                  # Le vecteur y (variable expliquée) correspond à la colonne 'tip'\n",
    "X = data.drop(columns=['tip'])   # La matrice X (variables explicatives) correspond aux autres colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On entraîne notre modèle avec 70% des données du dataset et on le valide avec les 30% restants : <br> - On entraîne notre modèle avec $y_{train}$ en fonction de $X_{train}$ <br> - On valide notre modèle avec $y_{test}$ en fonction de $X_{test}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La fonction train_test_split() permet de créer X_train, X_test, y_train et y_test automatiquement\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les colonnes 'sex', 'smoker',\t'day' et\t'time' contiennent des données catégorielles. On doit donc les représenter ordinalement pour pouvoir appliquer un modèle de régression linéaire dessus.\n",
    "### Voyont la méthode 'get_dummies( )' :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[[\"sex\",\"smoker\",\"day\",\"time\"]].nunique())  # Cette commande nous donne le nombre de valeurs uniques dans les colonnes catégorielles\n",
    "\n",
    "X_train_dummies = pd.get_dummies(X_train)  # Pour chaque colonne catégorielle, ont créé un nombre de colonnes égal au nombre de valeurs uniques qu'elle contient.\n",
    "X_test_dummies = pd.get_dummies(X_test)    # Si la ligne contient cette valeur, on lui donne la valeur 1, sinon 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.sample(3)  # Avant 'get_dummies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dummies.sample(3) # Après 'get_dummies'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maintenant qu'on a remplacé les données catégorielles en données ordinales, on peut entrainer notre modèle linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()  # On utilise un modèle linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_dummies = lr.fit(X_train_dummies, y_train) # On entraine le modèle avec y_train en fonction de X_train_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_dummies.score(X_test_dummies, y_test)  # On récupère le R^2 de notre modèle en le testant avec y_test en fonction de X_test_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afin d'améliorer les performances de notre modèle et de minimiser la loss function, il est intéressant de le scaler les données numériques entre 0 et 1. <br> Créons une méthode pour le faire automatiquement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On scale les colonnes numériques de notre dataset\n",
    "\n",
    "def valeurs_numeriques(X_train, X_test, model):                                # On précise à notre fonction le modèle de scaling à utiliser\n",
    "    columns = X_test._get_numeric_data().columns.values.tolist()               # On récupère les colonnes numériques sous forme de liste\n",
    "    model.fit(X_train[columns])                                                # ON FIT LE MODELE AVEC LES DONNEES D'ENTRAINEMENT ET NON DE TEST POUR EVITER LE DATALEAKAGE\n",
    "    df = pd.DataFrame(model.transform(X_test[columns]))                        # On tranforme notre modèle et on le converti en dataframe\n",
    "    return df.rename(columns={i:f'{columns[i]}' for i in range(len(columns))}) # On return le dataframe (on renomme les colonnes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voyont la méthode 'OneHotEncoder( )' pour transformer les valeurs catégorielles en valeurs ordinales :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()  # Méthode alternative à get_dummies() pour transformer les valeurs catégorielles en valeurs ordinales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On change les valeurs des colonnes catégorielles de notre dataset en valeurs ordinales\n",
    "\n",
    "def valeurs_categorielles(X_train, X_test):\n",
    "    columns = list(set(X.columns)-set(X_test._get_numeric_data().columns))   # On récupère les colonnes catégorielles sous forme de liste\n",
    "    ohe.fit(X_train[columns])                                                # ON FIT LE MODELE AVEC LES DONNEES D'ENTRAINEMENT ET NON DE TEST POUR EVITER LE DATALEAKAGE\n",
    "    return pd.DataFrame.sparse.from_spmatrix(ohe.transform(X_test[columns])) # On tranforme notre modèle et on le converti en dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créons une méthode créant un dataset scalé et avec uniquement des valeurs numériques/ordinales :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On concatène les colonnes ordinales et numériques après scaling\n",
    "\n",
    "def scaler(X_train, X_test, scaler): \n",
    "    return pd.concat([valeurs_categorielles(X_train, X_test), valeurs_numeriques(X_train, X_test, scaler)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appliquons notre méthode sur le dataset avec le modèle 'MinMaxScaler( )' :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mms = scaler(X_train, X_train, MinMaxScaler())  # On scale X_train\n",
    "X_test_mms = scaler(X_train, X_test, MinMaxScaler())    # On scale X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[['total_bill', 'size']].head(3) # Avant scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_mms[['total_bill', 'size']].head(3) # Après scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maintenant qu'on a remplacé les données catégorielles en données ordinales et scalé les données numériques, on peut entrainer notre modèle linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mms = lr.fit(X_train_mms, y_train)              # On entraîne le modèle avec y_train en fonction de X_train_mms\n",
    "print(f'R2 = {lr_mms.score(X_test_mms, y_test)}')  # On récupère le R^2 de notre modèle en le testant avec y_test en fonction de X_test_mms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Superposont sur un nuage de points les valeurs prédites par notre modèle $(y_{pred})$ et les valeurs réelles $(y_{test})$ en fonction de la colonne 'total_bill'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mms = lr_mms.predict(X_test_mms)  # On calcule y_pred en appliquant la méthode 'predict()' sur notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.scatter(X_test['total_bill'], y_test, label='y_test')\n",
    "plt.scatter(X_test['total_bill'], y_pred_mms, label='y_pred_mss')\n",
    "plt.xlabel('Total bill', fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On peut représenter d'autres variables explicatives en jouant sur la taille des points, leur couleur..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.scatter(X_test['total_bill'], y_test, label='y_test', s=np.exp(X_test['size']), c=pd.get_dummies(X_test['sex'])['Male'])\n",
    "plt.scatter(X_test['total_bill'], y_pred_mms, label='y_pred', s=np.exp(X_test['size']))\n",
    "plt.xlabel('Total bill', fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appliquons notre méthode avec le modèle 'StandardScaler( )' :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ss = scaler(X_train, X_train, StandardScaler())  # On scale X_train\n",
    "X_test_ss = scaler(X_train, X_test, StandardScaler())    # On scale X_test\n",
    "\n",
    "lr_ss = lr.fit(X_train_ss, y_train)              # On entraîne le modèle avec y_train en fonction de X_train_ss\n",
    "print(f'R2 = {lr_ss.score(X_test_ss, y_test)}')  # On récupère le R^2 de notre modèle en le testant avec y_test en fonction de X_test_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ss = lr_mms.predict(X_test_ss)  # On calcule y_pred en appliquant la méthode 'predict()' sur notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.scatter(X_test['total_bill'], y_test, label='y_test')\n",
    "plt.scatter(X_test['total_bill'], y_pred_ss, label='y_pred')\n",
    "plt.xlabel('Total bill', fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traçons la distribution des erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_error = y_test - y_pred_mms   # L'erreur correspond à la différence entre la valeur réelle et la valeur prédite\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.histplot(y_error, kde=True)\n",
    "plt.xlabel('Error')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('shims')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e588d92b224e11b16adbbadd39936dea13a6488171770263a646fc57f44563d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
